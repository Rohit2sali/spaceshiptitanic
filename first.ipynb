{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Activation, LeakyReLU\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import RMSprop, Nadam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8693, 14) (4277, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "...           ...        ...           ...     ...     ...                ...   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "...           ...  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "tdf = pd.read_csv('test.csv')\n",
    "print(df.shape, tdf.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/3/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>27.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nelly Carsoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/4/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lerome Peckers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>True</td>\n",
       "      <td>C/0/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>31.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sabih Unhearfus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>C/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>Meratz Caltilter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/5/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Brence Harperez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4272</th>\n",
       "      <td>9266_02</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1496/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>34.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jeron Peter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>9269_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>42.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>Matty Scheron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4274</th>\n",
       "      <td>9271_01</td>\n",
       "      <td>Mars</td>\n",
       "      <td>True</td>\n",
       "      <td>D/296/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jayrin Pore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>9273_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>D/297/P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>523.0</td>\n",
       "      <td>Kitakan Conale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>9277_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1498/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lilace Leonzaley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4277 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0013_01      Earth      True     G/3/S    TRAPPIST-1e  27.0  False   \n",
       "1        0018_01      Earth     False     F/4/S    TRAPPIST-1e  19.0  False   \n",
       "2        0019_01     Europa      True     C/0/S    55 Cancri e  31.0  False   \n",
       "3        0021_01     Europa     False     C/1/S    TRAPPIST-1e  38.0  False   \n",
       "4        0023_01      Earth     False     F/5/S    TRAPPIST-1e  20.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "4272     9266_02      Earth      True  G/1496/S    TRAPPIST-1e  34.0  False   \n",
       "4273     9269_01      Earth     False       NaN    TRAPPIST-1e  42.0  False   \n",
       "4274     9271_01       Mars      True   D/296/P    55 Cancri e   NaN  False   \n",
       "4275     9273_01     Europa     False   D/297/P            NaN   NaN  False   \n",
       "4276     9277_01      Earth      True  G/1498/S  PSO J318.5-22  43.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck              Name  \n",
       "0             0.0        0.0           0.0     0.0     0.0   Nelly Carsoning  \n",
       "1             0.0        9.0           0.0  2823.0     0.0    Lerome Peckers  \n",
       "2             0.0        0.0           0.0     0.0     0.0   Sabih Unhearfus  \n",
       "3             0.0     6652.0           0.0   181.0   585.0  Meratz Caltilter  \n",
       "4            10.0        0.0         635.0     0.0     0.0   Brence Harperez  \n",
       "...           ...        ...           ...     ...     ...               ...  \n",
       "4272          0.0        0.0           0.0     0.0     0.0       Jeron Peter  \n",
       "4273          0.0      847.0          17.0    10.0   144.0     Matty Scheron  \n",
       "4274          0.0        0.0           0.0     0.0     0.0       Jayrin Pore  \n",
       "4275          0.0     2680.0           0.0     0.0   523.0    Kitakan Conale  \n",
       "4276          0.0        0.0           0.0     0.0     0.0  Lilace Leonzaley  \n",
       "\n",
       "[4277 rows x 13 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet      201\n",
       "CryoSleep       217\n",
       "Cabin           199\n",
       "Destination     182\n",
       "Age             179\n",
       "VIP             203\n",
       "RoomService     181\n",
       "FoodCourt       183\n",
       "ShoppingMall    208\n",
       "Spa             183\n",
       "VRDeck          188\n",
       "Name            200\n",
       "Transported       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8693, 14) (4277, 13)\n"
     ]
    }
   ],
   "source": [
    "train_df = df.drop(columns=['Name', 'Cabin', 'PassengerId'])\n",
    "test_tdf = tdf.drop(columns=['Name', 'Cabin', 'PassengerId'])\n",
    "print(df.shape, tdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8693, 14) (4277, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\salir\\AppData\\Local\\Temp\\ipykernel_7044\\2349466253.py:8: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  train_df.loc[:, df_categorical.columns] = df_categorical.apply(lambda x: x.fillna(x.mode()[0]))\n",
      "C:\\Users\\salir\\AppData\\Local\\Temp\\ipykernel_7044\\2349466253.py:11: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_tdf.loc[:, tdf_categorical.columns] = tdf_categorical.apply(lambda x: x.fillna(x.mode()[0]))\n"
     ]
    }
   ],
   "source": [
    "df_numeric = train_df.select_dtypes(include=['number'])\n",
    "train_df.loc[:, df_numeric.columns] = df_numeric.fillna(df_numeric.mean())\n",
    "\n",
    "tdf_numeric = test_tdf.select_dtypes(include=['number'])\n",
    "test_tdf.loc[:, tdf_numeric.columns] = tdf_numeric.fillna(tdf_numeric.mean())\n",
    "\n",
    "df_categorical = train_df.select_dtypes(include=['object', 'category'])\n",
    "train_df.loc[:, df_categorical.columns] = df_categorical.apply(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "tdf_categorical = test_tdf.select_dtypes(include=['object', 'category'])\n",
    "test_tdf.loc[:, tdf_categorical.columns] = tdf_categorical.apply(lambda x: x.fillna(x.mode()[0]))\n",
    "print(df.shape, tdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6560"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['Cabin'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8693, 17) (4277, 16)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.get_dummies(train_df)\n",
    "test_tdf = pd.get_dummies(test_tdf)\n",
    "print(train_df.shape, test_tdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8693, 16) (8693,)\n"
     ]
    }
   ],
   "source": [
    "X = train_df.drop(columns='Transported')\n",
    "y = train_df['Transported']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8693, 16) (4277, 16)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X)\n",
    "X_test = scaler.fit_transform(test_tdf)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ML Algorithms\\myenv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">170</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m170\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> (3.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m771\u001b[0m (3.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> (3.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m771\u001b[0m (3.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10, activation='relu', input_shape=(16,)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6256 - loss: 0.6493 - val_accuracy: 0.7890 - val_loss: 0.4750\n",
      "Epoch 2/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7753 - loss: 0.4768 - val_accuracy: 0.7976 - val_loss: 0.4377\n",
      "Epoch 3/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7791 - loss: 0.4639 - val_accuracy: 0.7907 - val_loss: 0.4312\n",
      "Epoch 4/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7774 - loss: 0.4518 - val_accuracy: 0.7936 - val_loss: 0.4244\n",
      "Epoch 5/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7919 - loss: 0.4346 - val_accuracy: 0.8016 - val_loss: 0.4250\n",
      "Epoch 6/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7891 - loss: 0.4461 - val_accuracy: 0.7970 - val_loss: 0.4139\n",
      "Epoch 7/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7803 - loss: 0.4507 - val_accuracy: 0.7947 - val_loss: 0.4167\n",
      "Epoch 8/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7923 - loss: 0.4384 - val_accuracy: 0.7959 - val_loss: 0.4176\n",
      "Epoch 9/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7876 - loss: 0.4402 - val_accuracy: 0.8010 - val_loss: 0.4179\n",
      "Epoch 10/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7915 - loss: 0.4296 - val_accuracy: 0.7982 - val_loss: 0.4142\n",
      "Epoch 11/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7916 - loss: 0.4425 - val_accuracy: 0.7987 - val_loss: 0.4072\n",
      "Epoch 12/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7946 - loss: 0.4328 - val_accuracy: 0.8022 - val_loss: 0.4113\n",
      "Epoch 13/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7970 - loss: 0.4310 - val_accuracy: 0.7924 - val_loss: 0.4192\n",
      "Epoch 14/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.4384 - val_accuracy: 0.8062 - val_loss: 0.4075\n",
      "Epoch 15/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7913 - loss: 0.4410 - val_accuracy: 0.8016 - val_loss: 0.4145\n",
      "Epoch 16/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8033 - loss: 0.4253 - val_accuracy: 0.7953 - val_loss: 0.4134\n",
      "Epoch 17/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7964 - loss: 0.4325 - val_accuracy: 0.7999 - val_loss: 0.4107\n",
      "Epoch 18/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7978 - loss: 0.4270 - val_accuracy: 0.8028 - val_loss: 0.4095\n",
      "Epoch 19/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8025 - loss: 0.4280 - val_accuracy: 0.8028 - val_loss: 0.4078\n",
      "Epoch 20/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8036 - loss: 0.4251 - val_accuracy: 0.7987 - val_loss: 0.4143\n",
      "Epoch 21/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8024 - loss: 0.4211 - val_accuracy: 0.7964 - val_loss: 0.4050\n",
      "Epoch 22/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8013 - loss: 0.4291 - val_accuracy: 0.8079 - val_loss: 0.4061\n",
      "Epoch 23/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8058 - loss: 0.4232 - val_accuracy: 0.8051 - val_loss: 0.4059\n",
      "Epoch 24/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7976 - loss: 0.4257 - val_accuracy: 0.8039 - val_loss: 0.4071\n",
      "Epoch 25/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7871 - loss: 0.4422 - val_accuracy: 0.8045 - val_loss: 0.4040\n",
      "Epoch 26/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8012 - loss: 0.4201 - val_accuracy: 0.8045 - val_loss: 0.4038\n",
      "Epoch 27/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7980 - loss: 0.4242 - val_accuracy: 0.8022 - val_loss: 0.4103\n",
      "Epoch 28/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7891 - loss: 0.4357 - val_accuracy: 0.8016 - val_loss: 0.4167\n",
      "Epoch 29/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8033 - loss: 0.4212 - val_accuracy: 0.8062 - val_loss: 0.4104\n",
      "Epoch 30/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7997 - loss: 0.4224 - val_accuracy: 0.8062 - val_loss: 0.4016\n",
      "Epoch 31/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8002 - loss: 0.4200 - val_accuracy: 0.7976 - val_loss: 0.4171\n",
      "Epoch 32/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.4215 - val_accuracy: 0.8074 - val_loss: 0.4098\n",
      "Epoch 33/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.4283 - val_accuracy: 0.8051 - val_loss: 0.4120\n",
      "Epoch 34/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8075 - loss: 0.4092 - val_accuracy: 0.8079 - val_loss: 0.4078\n",
      "Epoch 35/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8029 - loss: 0.4220 - val_accuracy: 0.8085 - val_loss: 0.4040\n",
      "Epoch 36/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8104 - loss: 0.4129 - val_accuracy: 0.7976 - val_loss: 0.4191\n",
      "Epoch 37/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8130 - loss: 0.4130 - val_accuracy: 0.8062 - val_loss: 0.4096\n",
      "Epoch 38/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8019 - loss: 0.4202 - val_accuracy: 0.8074 - val_loss: 0.4072\n",
      "Epoch 39/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7974 - loss: 0.4209 - val_accuracy: 0.8045 - val_loss: 0.4102\n",
      "Epoch 40/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8109 - loss: 0.4089 - val_accuracy: 0.8091 - val_loss: 0.4030\n",
      "Epoch 41/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7972 - loss: 0.4238 - val_accuracy: 0.8056 - val_loss: 0.4090\n",
      "Epoch 42/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8007 - loss: 0.4247 - val_accuracy: 0.8051 - val_loss: 0.4070\n",
      "Epoch 43/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8057 - loss: 0.4200 - val_accuracy: 0.8033 - val_loss: 0.4165\n",
      "Epoch 44/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7985 - loss: 0.4239 - val_accuracy: 0.8085 - val_loss: 0.4082\n",
      "Epoch 45/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7953 - loss: 0.4352 - val_accuracy: 0.8033 - val_loss: 0.4115\n",
      "Epoch 46/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8052 - loss: 0.4119 - val_accuracy: 0.8056 - val_loss: 0.4100\n",
      "Epoch 47/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8105 - loss: 0.4083 - val_accuracy: 0.8074 - val_loss: 0.4074\n",
      "Epoch 48/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8003 - loss: 0.4228 - val_accuracy: 0.8016 - val_loss: 0.4121\n",
      "Epoch 49/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8043 - loss: 0.4188 - val_accuracy: 0.8102 - val_loss: 0.4070\n",
      "Epoch 50/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7881 - loss: 0.4317 - val_accuracy: 0.8062 - val_loss: 0.4064\n",
      "Epoch 51/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8034 - loss: 0.4156 - val_accuracy: 0.8091 - val_loss: 0.4105\n",
      "Epoch 52/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8028 - loss: 0.4184 - val_accuracy: 0.8028 - val_loss: 0.4215\n",
      "Epoch 53/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8005 - loss: 0.4251 - val_accuracy: 0.8068 - val_loss: 0.4068\n",
      "Epoch 54/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7957 - loss: 0.4207 - val_accuracy: 0.8085 - val_loss: 0.4136\n",
      "Epoch 55/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7970 - loss: 0.4292 - val_accuracy: 0.8045 - val_loss: 0.4066\n",
      "Epoch 56/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.4094 - val_accuracy: 0.8079 - val_loss: 0.4072\n",
      "Epoch 57/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8052 - loss: 0.4182 - val_accuracy: 0.8091 - val_loss: 0.4085\n",
      "Epoch 58/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8072 - loss: 0.4192 - val_accuracy: 0.8028 - val_loss: 0.4115\n",
      "Epoch 59/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8031 - loss: 0.4173 - val_accuracy: 0.8079 - val_loss: 0.4056\n",
      "Epoch 60/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8064 - loss: 0.4121 - val_accuracy: 0.8102 - val_loss: 0.4044\n",
      "Epoch 61/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8018 - loss: 0.4213 - val_accuracy: 0.8125 - val_loss: 0.4057\n",
      "Epoch 62/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8011 - loss: 0.4186 - val_accuracy: 0.8091 - val_loss: 0.4074\n",
      "Epoch 63/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7887 - loss: 0.4282 - val_accuracy: 0.8085 - val_loss: 0.4070\n",
      "Epoch 64/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8028 - loss: 0.4224 - val_accuracy: 0.8074 - val_loss: 0.4044\n",
      "Epoch 65/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8023 - loss: 0.4208 - val_accuracy: 0.8062 - val_loss: 0.4121\n",
      "Epoch 66/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8010 - loss: 0.4214 - val_accuracy: 0.8091 - val_loss: 0.4099\n",
      "Epoch 67/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8066 - loss: 0.4152 - val_accuracy: 0.8114 - val_loss: 0.4028\n",
      "Epoch 68/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8078 - loss: 0.4094 - val_accuracy: 0.8079 - val_loss: 0.4061\n",
      "Epoch 69/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7970 - loss: 0.4269 - val_accuracy: 0.8051 - val_loss: 0.4126\n",
      "Epoch 70/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 0.4268 - val_accuracy: 0.8085 - val_loss: 0.4094\n",
      "Epoch 71/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8072 - loss: 0.4121 - val_accuracy: 0.8091 - val_loss: 0.4057\n",
      "Epoch 72/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8052 - loss: 0.4158 - val_accuracy: 0.8079 - val_loss: 0.4108\n",
      "Epoch 73/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8041 - loss: 0.4203 - val_accuracy: 0.8068 - val_loss: 0.4061\n",
      "Epoch 74/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8093 - loss: 0.4115 - val_accuracy: 0.8102 - val_loss: 0.4082\n",
      "Epoch 75/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8116 - loss: 0.4089 - val_accuracy: 0.8062 - val_loss: 0.4139\n",
      "Epoch 76/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8048 - loss: 0.4154 - val_accuracy: 0.8114 - val_loss: 0.4102\n",
      "Epoch 77/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.4052 - val_accuracy: 0.8028 - val_loss: 0.4146\n",
      "Epoch 78/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8175 - loss: 0.4012 - val_accuracy: 0.8108 - val_loss: 0.4105\n",
      "Epoch 79/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8077 - loss: 0.4091 - val_accuracy: 0.8062 - val_loss: 0.4089\n",
      "Epoch 80/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8047 - loss: 0.4158 - val_accuracy: 0.8068 - val_loss: 0.4134\n",
      "Epoch 81/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8104 - loss: 0.4068 - val_accuracy: 0.8068 - val_loss: 0.4148\n",
      "Epoch 82/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8015 - loss: 0.4174 - val_accuracy: 0.8079 - val_loss: 0.4074\n",
      "Epoch 83/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8091 - loss: 0.4054 - val_accuracy: 0.8056 - val_loss: 0.4075\n",
      "Epoch 84/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8006 - loss: 0.4206 - val_accuracy: 0.8028 - val_loss: 0.4132\n",
      "Epoch 85/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8020 - loss: 0.4199 - val_accuracy: 0.8102 - val_loss: 0.4097\n",
      "Epoch 86/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8042 - loss: 0.4197 - val_accuracy: 0.8085 - val_loss: 0.4166\n",
      "Epoch 87/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8033 - loss: 0.4165 - val_accuracy: 0.8062 - val_loss: 0.4093\n",
      "Epoch 88/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7967 - loss: 0.4212 - val_accuracy: 0.8056 - val_loss: 0.4110\n",
      "Epoch 89/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8077 - loss: 0.4083 - val_accuracy: 0.8114 - val_loss: 0.4101\n",
      "Epoch 90/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8104 - loss: 0.4096 - val_accuracy: 0.8097 - val_loss: 0.4105\n",
      "Epoch 91/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8060 - loss: 0.4163 - val_accuracy: 0.8068 - val_loss: 0.4117\n",
      "Epoch 92/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.4123 - val_accuracy: 0.8039 - val_loss: 0.4170\n",
      "Epoch 93/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8056 - loss: 0.4122 - val_accuracy: 0.8056 - val_loss: 0.4103\n",
      "Epoch 94/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8046 - loss: 0.4148 - val_accuracy: 0.8085 - val_loss: 0.4051\n",
      "Epoch 95/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8056 - loss: 0.4049 - val_accuracy: 0.8045 - val_loss: 0.4124\n",
      "Epoch 96/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8054 - loss: 0.4152 - val_accuracy: 0.8056 - val_loss: 0.4092\n",
      "Epoch 97/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.4019 - val_accuracy: 0.8051 - val_loss: 0.4064\n",
      "Epoch 98/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8002 - loss: 0.4211 - val_accuracy: 0.8085 - val_loss: 0.4104\n",
      "Epoch 99/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8094 - loss: 0.4077 - val_accuracy: 0.8056 - val_loss: 0.4068\n",
      "Epoch 100/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8065 - loss: 0.4130 - val_accuracy: 0.8091 - val_loss: 0.4084\n",
      "Epoch 101/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8114 - loss: 0.4077 - val_accuracy: 0.8039 - val_loss: 0.4072\n",
      "Epoch 102/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8091 - loss: 0.4080 - val_accuracy: 0.8062 - val_loss: 0.4070\n",
      "Epoch 103/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.4065 - val_accuracy: 0.8016 - val_loss: 0.4186\n",
      "Epoch 104/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8059 - loss: 0.4138 - val_accuracy: 0.8062 - val_loss: 0.4070\n",
      "Epoch 105/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8028 - loss: 0.4151 - val_accuracy: 0.8062 - val_loss: 0.4100\n",
      "Epoch 106/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8039 - loss: 0.4160 - val_accuracy: 0.8091 - val_loss: 0.4122\n",
      "Epoch 107/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8028 - loss: 0.4142 - val_accuracy: 0.8074 - val_loss: 0.4102\n",
      "Epoch 108/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8009 - loss: 0.4169 - val_accuracy: 0.8022 - val_loss: 0.4056\n",
      "Epoch 109/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8021 - loss: 0.4164 - val_accuracy: 0.8033 - val_loss: 0.4097\n",
      "Epoch 110/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8058 - loss: 0.4131 - val_accuracy: 0.8022 - val_loss: 0.4192\n",
      "Epoch 111/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8066 - loss: 0.4116 - val_accuracy: 0.8033 - val_loss: 0.4071\n",
      "Epoch 112/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8156 - loss: 0.4070 - val_accuracy: 0.8074 - val_loss: 0.4131\n",
      "Epoch 113/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8089 - loss: 0.4088 - val_accuracy: 0.7987 - val_loss: 0.4153\n",
      "Epoch 114/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8026 - loss: 0.4143 - val_accuracy: 0.7982 - val_loss: 0.4062\n",
      "Epoch 115/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8046 - loss: 0.4145 - val_accuracy: 0.8010 - val_loss: 0.4064\n",
      "Epoch 116/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8064 - loss: 0.4123 - val_accuracy: 0.8010 - val_loss: 0.4073\n",
      "Epoch 117/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8121 - loss: 0.4067 - val_accuracy: 0.8039 - val_loss: 0.4140\n",
      "Epoch 118/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8023 - loss: 0.4164 - val_accuracy: 0.8016 - val_loss: 0.4087\n",
      "Epoch 119/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8005 - loss: 0.4141 - val_accuracy: 0.7999 - val_loss: 0.4168\n",
      "Epoch 120/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8042 - loss: 0.4106 - val_accuracy: 0.8039 - val_loss: 0.4193\n",
      "Epoch 121/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.4101 - val_accuracy: 0.8068 - val_loss: 0.4095\n",
      "Epoch 122/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8147 - loss: 0.4096 - val_accuracy: 0.8097 - val_loss: 0.4143\n",
      "Epoch 123/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8083 - loss: 0.4122 - val_accuracy: 0.8068 - val_loss: 0.4163\n",
      "Epoch 124/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8099 - loss: 0.4113 - val_accuracy: 0.8010 - val_loss: 0.4150\n",
      "Epoch 125/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8082 - loss: 0.4157 - val_accuracy: 0.8028 - val_loss: 0.4132\n",
      "Epoch 126/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8088 - loss: 0.4080 - val_accuracy: 0.8085 - val_loss: 0.4133\n",
      "Epoch 127/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.4142 - val_accuracy: 0.8045 - val_loss: 0.4131\n",
      "Epoch 128/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7994 - loss: 0.4210 - val_accuracy: 0.8028 - val_loss: 0.4099\n",
      "Epoch 129/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8128 - loss: 0.4001 - val_accuracy: 0.8022 - val_loss: 0.4075\n",
      "Epoch 130/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7979 - loss: 0.4210 - val_accuracy: 0.7999 - val_loss: 0.4120\n",
      "Epoch 131/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8091 - loss: 0.4092 - val_accuracy: 0.7999 - val_loss: 0.4143\n",
      "Epoch 132/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8048 - loss: 0.4081 - val_accuracy: 0.8045 - val_loss: 0.4118\n",
      "Epoch 133/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8038 - loss: 0.4103 - val_accuracy: 0.8045 - val_loss: 0.4215\n",
      "Epoch 134/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8022 - loss: 0.4114 - val_accuracy: 0.8005 - val_loss: 0.4153\n",
      "Epoch 135/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8023 - loss: 0.4117 - val_accuracy: 0.8016 - val_loss: 0.4176\n",
      "Epoch 136/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8074 - loss: 0.4071 - val_accuracy: 0.8045 - val_loss: 0.4128\n",
      "Epoch 137/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8096 - loss: 0.4092 - val_accuracy: 0.8056 - val_loss: 0.4120\n",
      "Epoch 138/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8064 - loss: 0.4092 - val_accuracy: 0.8016 - val_loss: 0.4185\n",
      "Epoch 139/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8109 - loss: 0.4130 - val_accuracy: 0.7970 - val_loss: 0.4133\n",
      "Epoch 140/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7986 - loss: 0.4233 - val_accuracy: 0.8010 - val_loss: 0.4161\n",
      "Epoch 141/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8042 - loss: 0.4047 - val_accuracy: 0.8033 - val_loss: 0.4125\n",
      "Epoch 142/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8065 - loss: 0.4072 - val_accuracy: 0.8005 - val_loss: 0.4160\n",
      "Epoch 143/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8030 - loss: 0.4144 - val_accuracy: 0.7970 - val_loss: 0.4207\n",
      "Epoch 144/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8007 - loss: 0.4209 - val_accuracy: 0.8022 - val_loss: 0.4114\n",
      "Epoch 145/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8010 - loss: 0.4138 - val_accuracy: 0.8016 - val_loss: 0.4164\n",
      "Epoch 146/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8144 - loss: 0.4026 - val_accuracy: 0.8022 - val_loss: 0.4225\n",
      "Epoch 147/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8033 - loss: 0.4111 - val_accuracy: 0.8005 - val_loss: 0.4101\n",
      "Epoch 148/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8150 - loss: 0.4033 - val_accuracy: 0.8028 - val_loss: 0.4149\n",
      "Epoch 149/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8137 - loss: 0.4047 - val_accuracy: 0.8016 - val_loss: 0.4205\n",
      "Epoch 150/150\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8047 - loss: 0.4116 - val_accuracy: 0.8033 - val_loss: 0.4109\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y, epochs=150, validation_split=0.2, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7751916 ],\n",
       "       [0.        ],\n",
       "       [0.97913265],\n",
       "       ...,\n",
       "       [0.9602292 ],\n",
       "       [1.        ],\n",
       "       [0.8809921 ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(test_tdf)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.where(pred > 0.5, 1, 0)\n",
    "pred = pred.flatten()\n",
    "pred = pred.astype(bool)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'PassengerId' : tdf['PassengerId'],\n",
    "    'Transported' : pred\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_30\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_30\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_114 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,700</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_115 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_116 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_117 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">151</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_114 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m1,700\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_115 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │        \u001b[38;5;34m20,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_116 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │        \u001b[38;5;34m30,150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_117 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m151\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,201</span> (203.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,201\u001b[0m (203.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,201</span> (203.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,201\u001b[0m (203.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(100, activation='tanh', input_shape=(16,)))\n",
    "#model2.add(BatchNormalization())\n",
    "model2.add(Dense(200, activation='tanh'))\n",
    "#model2.add(BatchNormalization())\n",
    "#model2.add(Dense(, activation='relu'))\n",
    "model2.add(Dense(150, activation='tanh'))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "\n",
    "#optimizer = RMSprop(alpha=(0.1))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7660 - loss: 0.4979 - val_accuracy: 0.7890 - val_loss: 0.4239\n",
      "Epoch 2/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.4602 - val_accuracy: 0.7959 - val_loss: 0.4291\n",
      "Epoch 3/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7904 - loss: 0.4505 - val_accuracy: 0.7959 - val_loss: 0.4168\n",
      "Epoch 4/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.4547 - val_accuracy: 0.8022 - val_loss: 0.4188\n",
      "Epoch 5/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7850 - loss: 0.4438 - val_accuracy: 0.7936 - val_loss: 0.4247\n",
      "Epoch 6/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7923 - loss: 0.4444 - val_accuracy: 0.7999 - val_loss: 0.4229\n",
      "Epoch 7/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7913 - loss: 0.4389 - val_accuracy: 0.8085 - val_loss: 0.4118\n",
      "Epoch 8/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.4395 - val_accuracy: 0.8016 - val_loss: 0.4089\n",
      "Epoch 9/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7853 - loss: 0.4450 - val_accuracy: 0.8016 - val_loss: 0.4114\n",
      "Epoch 10/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7917 - loss: 0.4414 - val_accuracy: 0.8045 - val_loss: 0.4059\n",
      "Epoch 11/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8002 - loss: 0.4286 - val_accuracy: 0.8051 - val_loss: 0.4114\n",
      "Epoch 12/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7956 - loss: 0.4329 - val_accuracy: 0.7936 - val_loss: 0.4224\n",
      "Epoch 13/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: 0.4310 - val_accuracy: 0.7901 - val_loss: 0.4344\n",
      "Epoch 14/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.4385 - val_accuracy: 0.8033 - val_loss: 0.4169\n",
      "Epoch 15/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7962 - loss: 0.4271 - val_accuracy: 0.7976 - val_loss: 0.4211\n",
      "Epoch 16/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7923 - loss: 0.4311 - val_accuracy: 0.7941 - val_loss: 0.4145\n",
      "Epoch 17/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7978 - loss: 0.4258 - val_accuracy: 0.8016 - val_loss: 0.4121\n",
      "Epoch 18/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7962 - loss: 0.4274 - val_accuracy: 0.7987 - val_loss: 0.4081\n",
      "Epoch 19/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7988 - loss: 0.4303 - val_accuracy: 0.8033 - val_loss: 0.4110\n",
      "Epoch 20/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.4360 - val_accuracy: 0.8016 - val_loss: 0.4032\n",
      "Epoch 21/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7988 - loss: 0.4374 - val_accuracy: 0.8085 - val_loss: 0.4028\n",
      "Epoch 22/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7931 - loss: 0.4323 - val_accuracy: 0.7987 - val_loss: 0.4102\n",
      "Epoch 23/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7913 - loss: 0.4337 - val_accuracy: 0.8074 - val_loss: 0.4123\n",
      "Epoch 24/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.4275 - val_accuracy: 0.7993 - val_loss: 0.4202\n",
      "Epoch 25/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7980 - loss: 0.4326 - val_accuracy: 0.8005 - val_loss: 0.4063\n",
      "Epoch 26/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8051 - loss: 0.4135 - val_accuracy: 0.8045 - val_loss: 0.4005\n",
      "Epoch 27/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.4089 - val_accuracy: 0.8005 - val_loss: 0.4016\n",
      "Epoch 28/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.4110 - val_accuracy: 0.7999 - val_loss: 0.4084\n",
      "Epoch 29/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7959 - loss: 0.4193 - val_accuracy: 0.7970 - val_loss: 0.4189\n",
      "Epoch 30/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7985 - loss: 0.4177 - val_accuracy: 0.7987 - val_loss: 0.4129\n",
      "Epoch 31/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8123 - loss: 0.4031 - val_accuracy: 0.8028 - val_loss: 0.4072\n",
      "Epoch 32/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8041 - loss: 0.4152 - val_accuracy: 0.8033 - val_loss: 0.4066\n",
      "Epoch 33/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8026 - loss: 0.4132 - val_accuracy: 0.8028 - val_loss: 0.4065\n",
      "Epoch 34/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8009 - loss: 0.4132 - val_accuracy: 0.8033 - val_loss: 0.4075\n",
      "Epoch 35/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7987 - loss: 0.4144 - val_accuracy: 0.7987 - val_loss: 0.4111\n",
      "Epoch 36/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8033 - loss: 0.4115 - val_accuracy: 0.7982 - val_loss: 0.4127\n",
      "Epoch 37/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7965 - loss: 0.4200 - val_accuracy: 0.7947 - val_loss: 0.4203\n",
      "Epoch 38/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.4018 - val_accuracy: 0.8016 - val_loss: 0.4096\n",
      "Epoch 39/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8053 - loss: 0.4026 - val_accuracy: 0.7941 - val_loss: 0.4207\n",
      "Epoch 40/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8053 - loss: 0.4089 - val_accuracy: 0.8028 - val_loss: 0.4094\n",
      "Epoch 41/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8098 - loss: 0.3945 - val_accuracy: 0.7987 - val_loss: 0.4155\n",
      "Epoch 42/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8024 - loss: 0.4105 - val_accuracy: 0.8033 - val_loss: 0.4082\n",
      "Epoch 43/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8086 - loss: 0.4062 - val_accuracy: 0.7987 - val_loss: 0.4091\n",
      "Epoch 44/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8155 - loss: 0.3897 - val_accuracy: 0.7930 - val_loss: 0.4201\n",
      "Epoch 45/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8146 - loss: 0.3967 - val_accuracy: 0.8039 - val_loss: 0.4072\n",
      "Epoch 46/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8042 - loss: 0.4117 - val_accuracy: 0.8028 - val_loss: 0.4083\n",
      "Epoch 47/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8152 - loss: 0.3921 - val_accuracy: 0.8028 - val_loss: 0.4123\n",
      "Epoch 48/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8132 - loss: 0.3950 - val_accuracy: 0.8039 - val_loss: 0.4185\n",
      "Epoch 49/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.3908 - val_accuracy: 0.8022 - val_loss: 0.4180\n",
      "Epoch 50/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8117 - loss: 0.3971 - val_accuracy: 0.7982 - val_loss: 0.4121\n",
      "Epoch 51/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8164 - loss: 0.3974 - val_accuracy: 0.8005 - val_loss: 0.4136\n",
      "Epoch 52/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8130 - loss: 0.4003 - val_accuracy: 0.7999 - val_loss: 0.4124\n",
      "Epoch 53/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8212 - loss: 0.3834 - val_accuracy: 0.7959 - val_loss: 0.4234\n",
      "Epoch 54/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8164 - loss: 0.3880 - val_accuracy: 0.7970 - val_loss: 0.4180\n",
      "Epoch 55/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8183 - loss: 0.3865 - val_accuracy: 0.7901 - val_loss: 0.4321\n",
      "Epoch 56/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8161 - loss: 0.3947 - val_accuracy: 0.7982 - val_loss: 0.4217\n",
      "Epoch 57/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8231 - loss: 0.3800 - val_accuracy: 0.8005 - val_loss: 0.4270\n",
      "Epoch 58/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8216 - loss: 0.3805 - val_accuracy: 0.8005 - val_loss: 0.4308\n",
      "Epoch 59/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.3883 - val_accuracy: 0.8010 - val_loss: 0.4273\n",
      "Epoch 60/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8151 - loss: 0.3895 - val_accuracy: 0.7964 - val_loss: 0.4307\n",
      "Epoch 61/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8216 - loss: 0.3793 - val_accuracy: 0.7953 - val_loss: 0.4288\n",
      "Epoch 62/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.3732 - val_accuracy: 0.7970 - val_loss: 0.4235\n",
      "Epoch 63/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8170 - loss: 0.3824 - val_accuracy: 0.7999 - val_loss: 0.4190\n",
      "Epoch 64/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8248 - loss: 0.3747 - val_accuracy: 0.7993 - val_loss: 0.4265\n",
      "Epoch 65/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8248 - loss: 0.3779 - val_accuracy: 0.7752 - val_loss: 0.4367\n",
      "Epoch 66/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8336 - loss: 0.3618 - val_accuracy: 0.7924 - val_loss: 0.4290\n",
      "Epoch 67/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8227 - loss: 0.3740 - val_accuracy: 0.7901 - val_loss: 0.4358\n",
      "Epoch 68/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8229 - loss: 0.3715 - val_accuracy: 0.7959 - val_loss: 0.4317\n",
      "Epoch 69/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8349 - loss: 0.3644 - val_accuracy: 0.7901 - val_loss: 0.4355\n",
      "Epoch 70/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8344 - loss: 0.3594 - val_accuracy: 0.7907 - val_loss: 0.4318\n",
      "Epoch 71/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.3652 - val_accuracy: 0.7936 - val_loss: 0.4424\n",
      "Epoch 72/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8252 - loss: 0.3689 - val_accuracy: 0.7918 - val_loss: 0.4400\n",
      "Epoch 73/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.3602 - val_accuracy: 0.7907 - val_loss: 0.4383\n",
      "Epoch 74/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8236 - loss: 0.3671 - val_accuracy: 0.7959 - val_loss: 0.4368\n",
      "Epoch 75/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8367 - loss: 0.3592 - val_accuracy: 0.7936 - val_loss: 0.4434\n",
      "Epoch 76/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8329 - loss: 0.3577 - val_accuracy: 0.7895 - val_loss: 0.4432\n",
      "Epoch 77/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8319 - loss: 0.3566 - val_accuracy: 0.7895 - val_loss: 0.4472\n",
      "Epoch 78/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.3539 - val_accuracy: 0.7884 - val_loss: 0.4604\n",
      "Epoch 79/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8287 - loss: 0.3521 - val_accuracy: 0.7844 - val_loss: 0.4449\n",
      "Epoch 80/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.3493 - val_accuracy: 0.7872 - val_loss: 0.4472\n",
      "Epoch 81/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.3513 - val_accuracy: 0.7907 - val_loss: 0.4563\n",
      "Epoch 82/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.3519 - val_accuracy: 0.7890 - val_loss: 0.4540\n",
      "Epoch 83/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.3361 - val_accuracy: 0.7872 - val_loss: 0.4468\n",
      "Epoch 84/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8503 - loss: 0.3273 - val_accuracy: 0.7838 - val_loss: 0.4565\n",
      "Epoch 85/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.3343 - val_accuracy: 0.7769 - val_loss: 0.4622\n",
      "Epoch 86/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.3400 - val_accuracy: 0.7878 - val_loss: 0.4566\n",
      "Epoch 87/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8447 - loss: 0.3415 - val_accuracy: 0.7821 - val_loss: 0.4747\n",
      "Epoch 88/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8405 - loss: 0.3415 - val_accuracy: 0.7901 - val_loss: 0.4569\n",
      "Epoch 89/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8460 - loss: 0.3313 - val_accuracy: 0.7872 - val_loss: 0.4596\n",
      "Epoch 90/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8446 - loss: 0.3320 - val_accuracy: 0.7861 - val_loss: 0.4594\n",
      "Epoch 91/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8444 - loss: 0.3301 - val_accuracy: 0.7867 - val_loss: 0.4722\n",
      "Epoch 92/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8381 - loss: 0.3327 - val_accuracy: 0.7861 - val_loss: 0.4668\n",
      "Epoch 93/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8479 - loss: 0.3297 - val_accuracy: 0.7913 - val_loss: 0.4732\n",
      "Epoch 94/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8410 - loss: 0.3366 - val_accuracy: 0.7757 - val_loss: 0.4751\n",
      "Epoch 95/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8565 - loss: 0.3194 - val_accuracy: 0.7913 - val_loss: 0.4691\n",
      "Epoch 96/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8498 - loss: 0.3221 - val_accuracy: 0.7872 - val_loss: 0.4860\n",
      "Epoch 97/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8507 - loss: 0.3204 - val_accuracy: 0.7844 - val_loss: 0.4787\n",
      "Epoch 98/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8583 - loss: 0.3200 - val_accuracy: 0.7849 - val_loss: 0.4862\n",
      "Epoch 99/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8588 - loss: 0.3194 - val_accuracy: 0.7890 - val_loss: 0.4850\n",
      "Epoch 100/100\n",
      "\u001b[1m218/218\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 0.3162 - val_accuracy: 0.7855 - val_loss: 0.4961\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(X_train, y, epochs=100, validation_split=0.2, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = model2.predict(X_test)\n",
    "pred2 = np.where(pred2 > 0.5, 1, 0)\n",
    "pred2 = pred2.flatten()\n",
    "pred2 = pred2.astype(bool)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'PassengerId' : tdf['PassengerId'],\n",
    "    'Transported' : pred2\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
